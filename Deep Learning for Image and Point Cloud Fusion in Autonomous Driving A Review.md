# Deep Learning for Image and Point Cloud Fusion in Autonomous Driving: A Review



# Abstract

自动驾驶汽车在过去几年中得到了快速发展。然而，由于驾驶环境的复杂性和动态性，实现完全自主并非易事。因此，自动驾驶汽车配备了一套不同的传感器，以确保稳健、准确的环境感知。特别是，相机激光雷达融合正成为一个新兴的研究主题。然而，到目前为止，还没有关于基于深度学习的相机激光雷达融合方法的批判性综述。为了弥合这一差距并激励未来的研究，本文致力于回顾最近利用图像和点云的基于深度学习的数据融合方法。这篇综述简要概述了图像和点云数据处理的深度学习。其次，深入回顾了相机激光雷达融合方法在深度完成、目标检测、语义分割、跟踪和在线跨传感器校准方面的应用，这些方法是根据各自的融合水平进行组织的。此外，我们在公开的数据集上比较了这些方法。最后，我们发现了当前学术研究与现实应用之间的差距和过度关注的挑战。基于这些观察，我们提供了我们的见解，并指出了有希望的研究方向。

# I. INTRODUCTION

最近在深度学习和传感器技术方面的突破推动了自动驾驶技术的快速发展，这有可能提高道路安全、交通效率和人员流动性\[1][2][3]。然而，技术挑战和外周感觉传感器的成本限制了目前自动驾驶系统在少量封闭和受控环境中的应用。一个关键的挑战是实时获得对车辆3D周围环境的足够准确的理解。为此，传感器融合已成为一个新兴的研究主题，它利用具有互补特性的多种传感器来增强感知并降低成本。

特别是，最近的深度学习进步显着提高了相机-LiDAR融合算法的性能。相机和LiDAR具有互补特性，这使得与其他传感器融合配置（雷达-相机、LiDAR-雷达等）相比，相机-LiDAR融合模型更加有效和流行。更具体地说，基于视觉的感知系统在低成本下取得令人满意的性能，往往超过人类专家\[4][5]。然而，单相机感知系统无法提供可靠的3D几何形状，这对自动驾驶来说是必不可少的\[6][7]。另一方面，立体相机可以提供3D几何形状，但这样做计算成本高，并且在高遮挡和无纹理环境中难以处理\[8]\[9][10]。此外，基于相机的感知系统在复杂或恶劣的照明条件下运行困难，这限制了它们的全天候能力[11]。相反，LiDAR可以提供高精度的3D几何形状，并且不随环境光而变化。但是，移动式LiDAR受到低分辨率（从16到128个通道）、低刷新率（10Hz）、恶劣天气条件（大雨、雾和雪）和高成本的限制。为了缓解这些挑战，许多研究将这两种互补的传感器结合起来，并展示了比单模态方法显著的性能优势。因此，本文重点介绍当前用于相机-LiDAR融合的深度学习融合策略。

相机-LiDAR融合是一项非平凡的任务。首先，相机通过将其投影到图像平面上来记录真实世界，而点云保留3D几何形状。此外，就数据结构而言，点云是不规则的、无序的和连续的，而图像是规则的、有序的和离散的。点云和图像之间的这些特征差异导致了不同的特征提取方法。在图1中，比较了图像和点的特征。

![image-20231215170114995](C:\Users\ling\AppData\Roaming\Typora\typora-user-images\image-20231215170114995.png)

以前关于多模态数据融合的深度学习方法的评论文章\[12][13]涵盖了广泛的传感器，包括雷达、相机、LiDAR、超声波、IMU、里程计、全球导航卫星系统(GNSS)和高清地图。本文仅关注相机-LiDAR融合，因此能够对单个方法进行更详细的评论。此外，我们涵盖了更广泛的与感知相关的主题(深度补全、动态和静态目标检测、语义分割、跟踪和在线跨传感器校准)，这些主题相互关联，并未完全包含在之前的评论文章[13]中。本文的贡献总结如下：

• 据我们所知，本文是第一篇专注于自动驾驶中基于图像和点云融合的深度学习方法的综述，包括深度补全、动态和静态目标检测、语义分割、跟踪和在线跨传感器校准。

• 本文组织和评论基于它们的融合方法。此外，本文还介绍了2014-2020年最新的概述和性能比较，涵盖了最先进的相机-LiDAR融合方法。

• 本文提出了被忽视的公开问题，如开放集检测和传感器无关框架，这对于自动驾驶技术的实际部署至关重要。此外，还总结了趋势和可能的挑战研究方向。

本文第二部分简要概述了深度学习方法在图像和点云数据上的应用。第三部分至第八部分分别介绍了基于相机-LiDAR的深度补全、动态目标检测、静态目标检测、语义分割、目标跟踪和在线传感器校准的综述。第七部分讨论了趋势、公开挑战和有前景的方向。最后，第八部分给出了总结。图2展示了本文的总体结构和相应的话题。

![image-20231215170552852](C:\Users\ling\AppData\Roaming\Typora\typora-user-images\image-20231215170552852.png)

# II. A BRIEF REVIEW OF DEEP LEARNING

## A. Deep Learning on Image

卷积神经网络（CNN）是用于图像处理和理解的最高效和最强大的深度学习模型之一。与多层感知器（MLP）相比，CNN具有平移不变性，具有更少的权重并利用层次模式，从而使其在图像语义提取方面非常高效。CNN的隐藏层由一系列卷积层、批量归一化层、激活层和池化层组成，这些层端到端训练。这种层次结构提取图像特征，增加抽象层次和感受野，使学习高级语义成为可能。

## B. Deep Learning on Point Cloud

点云是一组数据点，是LiDAR对检测到的物体表面的测量结果。就数据结构而言，点云是稀疏的、不规则的、无序的和连续的。点云以3D结构和每个点的特征（反射强度、颜色、法向量等）编码信息，它对尺度、刚性变换和排列具有不变性。这些特征使得对点云的特征提取对于现有的深度学习模型来说具有挑战性，这需要修改现有模型或开发新模型。因此，本节重点介绍用于点云处理的常见方法。

1)基于体素表示的方法：体素表示将点云分割为固定分辨率的3D网格，其中每个网格/体素的特征是手工设计或学习的。这种表示与标准的3D卷积相兼容[14]-[16]。在[17]中提出了几种技术，以减少过度拟合、方向敏感性和捕获物体的内部结构。然而，体素表示在体素化过程中失去了空间分辨率和精细的3D几何形状，这限制了其性能。此外，增加其空间分辨率（更密集的体素）的努力会导致计算和内存占用按比例增长，使其无法扩展。

2)基于索引/树表示的方法：为了缓解高空间分辨率和计算成本之间的限制，提出了利用树形数据结构的自适应分辨率划分方法，例如kd-树\[18][19]，八叉树\[20]\[21][22]。通过将点云分成一系列不平衡的树，可以根据点密度对区域进行划分。这使得具有较低点密度的区域具有较低的分辨率，从而减少了不必要的计算和内存占用。沿预构建的树结构提取点特征。

3)基于2D视图表示的方法：2D视图/多视图是通过将点云投影到多个2D视图平面上生成的。这些渲染的多视图图像可以通过标准的2D卷积进行处理，并通过视图池化层从这些视图中聚合特征[23]。因此，通过将点云转换为图像来解决排列不变性问题，并通过聚合来自不同视图的特征来实现平移不变性。Qi等人[17]将体素表示与通过球体渲染生成的多视图相结合。不幸的是，2D视图方法在视图渲染过程中丢失了3D几何信息，并且难以进行每点标签预测[19]。

4)基于图表示的方法：点云可以表示为图，并且可以在空间或谱域上对图实施类似卷积的操作[24][25][26]。对于空间域中的图卷积，操作是通过在空间上相邻的点上的多层感知器（MLP）进行的。谱域上的图卷积将卷积扩展为通过拉普拉斯谱在图上的谱滤波[27][28][29]。

5)基于点的表示方法：基于点的表示方法在不将其转换为中间数据表示的情况下消费点云。该方向上的早期工作使用共享的多层感知器（MLP）来处理点云\[30][31]，而最近的工作则集中在为点定义专门的卷积运算[32]-[38]。

直接在点云上进行学习的开创性工作之一是PointNet\[30][31]，它采用独立的T-Net模块对齐点云，并使用共享的MLP处理各个点以进行每点特征提取。PointNet的计算复杂度随输入数量的增加而线性增加，与基于体素的方法相比，使其更具可扩展性。为了实现排列不变性，通过共享MLP提取逐点特征，这些特征对于所有点都是相同的。这些特征通过对称操作（即最大池化）进行聚合，这也是排列不变的。PointNet的特征提取过程定义为：
$$
g(\{x_1,...,x_n\})\approx f_{sym}(h(x_1),...,h(x_n))
$$
其中x表示输入点，h表示每点特征提取函数（即共享的MLP），fsym表示对称函数（即最大池化），g是我们想要近似的一般函数。

然而，PointNet未能在不同层次上提取局部点间几何。为了缓解这一挑战，Qi等人[30]扩展了PointNet，通过将点分组为多个集合并在局部应用PointNets来从不同层次提取特征。为了降低PointNet++[30]的计算和内存成本，RandLA-Net[39]分层堆叠了随机点采样模块和基于注意力的局部特征聚合模块，以逐步增加感受野，同时保持高效率。

与基于PointNet的方法不同，点对之间的空间关系在点对卷积中被明确建模。点对卷积旨在将标准的2D离散卷积推广到连续的3D空间。主要的挑战是使用MLP在PointConv[40]和相关函数在KPConv[38]和PCNN[33]中替换标准卷积中的离散权重滤波器。更具体地说，PCNN[33]将卷积核定义为具有权重的3D点。高斯相关函数用于计算给定3D坐标处的权重矩阵，该函数取核点和输入点的坐标。KPConv[38]遵循这一想法，但使用线性相关函数。此外，KPConvs[38]按层次应用于局部点补丁，这与标准CNN的概念相似。在3D连续空间中，输入点$x\in \mathbb{R}^3$的通用点对卷积$\mathcal{F}$定义为：
$$
(\mathcal{F}*h)(x)=\sum_{x_i\in \mathcal{N}_x}h(x_i-x)f_i
$$
其中h是每点核函数，它在给定输入点和核点的坐标的情况下计算加权矩阵。xi和fi是x的第i个相邻点及其对应特征（强度、颜色等）。Nx是输入点x的所有相邻点，它们是使用KNN或半径邻域确定的。
